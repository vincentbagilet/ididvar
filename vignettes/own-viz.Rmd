---
title: "Own visualizations"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Own visualizations}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r load_packages, message=FALSE}
library(ididvar)
library(tigris)
library(dplyr)
library(ggplot2)
```

This package exists to facilitate the computation and analysis of identifying variation weights. It therefore includes a set of functions to quickly visualize those weights. These functions have names starting by `idid_viz`. However, one may want to *customize* their graphs or build their own. 

This vignette **provides code that can easily be copied/pasted to make your own customized plots**, going beyond the quick but less customizable functions provided in the package.

## Making a plot

The workflow to make a plot from scratch is straightforward: 

1. Add a `weight` variable to the data set. Optionally, one can add a `contrib` dummy. For that we need to determine the contribution threshold. Here I use the `idid_contrib_threshold` to find a weight threshold below which removing observations does not change the point estimate or the standard error of the estimate of interest by more than a given proportion.
2. Compute the weights at a group level of interest (here state level) by summing weights of observations in this group.
3. Make a plot



Let's assume we have already ran the regression of interest and a `sf` object with our data.

```{r run_reg}
data_state_clean <- state.x77 |> 
  as_tibble() |> 
  mutate(state_name = rownames(state.x77), .before = 1) 

reg <- data_state_clean |> 
  lm(formula = Illiteracy ~  Income + Population + `Life Exp` + Frost)

states_sf <- 
  tigris::states(cb = TRUE, resolution = "20m", progress_bar = FALSE) |>
  tigris::shift_geometry() |> 
  rename(state_name = NAME)
```


We can then add a `weight` variable to our dataset, along with a `contrib` dummy. We then compute our weight and mean contribution at the state level, *i.e.*, at the level at which we want build our choropleth map. Note that this step is useless here as our data is already at the state level. Next, we compare the weights to the average weight (the inverse of the number of observations) and take its log10. This step is crucial to then be able to apply the `scale_fill_idid` color scale.

```{r agg_weights, fig.asp=0.8}
data_state_weights <- data_state_clean |> 
  mutate(
    weight = idid_weights(reg, "Income"),
    contrib = weight > idid_contrib_threshold(reg, "Income")
  ) |> 
  group_by(state_name) |> 
  summarise(
    weight = sum(weight, na.rm = TRUE), 
    contrib = mean(contrib, na.rm = TRUE),
    .groups = "drop"
  ) |> 
  mutate(weight_log = log10(weight * length(weight))) 
```

We can then merge the data to the shape file and make the graphs of interest.

```{r map_weights, fig.asp=0.8}
data_sf <- states_sf |> 
  full_join(data_state_weights, by = join_by(state_name)) 

data_sf |> 
  ggplot() +
  geom_sf(aes(fill = weight_log), color = "white", linewidth = 0.1) +
  theme_idid() +
  scale_fill_idid() +
  labs(
    title = "Distribution of Identifying Variation Weights",
    fill = "Weight, compared to the average weight"
  ) +
  theme(axis.text.y = element_blank(), 
        axis.text.x = element_blank())

data_sf |> 
  ggplot() +
  geom_sf(aes(fill = contrib), color = "white", linewidth = 0.1) +
  theme_idid() +
  scale_fill_gradient(low = "#FBE2C5", high = "#300D49") +
  labs(
    title = "Distribution of contributing observations per state",
    fill = "Share of contributing observations",
    caption = "In this particular example, there is only one observation per state.\nThe shares are threfore 0 or 1."
  ) +
  theme(axis.text.y = element_blank(), 
        axis.text.x = element_blank())
``` 

The maps produced in this document are not particularly instructive since the regression model is paritcularly naive.

<!-- # Why keeping the idid scale -->

<!-- I argue for keeping the idid scale -->

## Relationship between x and y

One may want to visualize the weights as well as the relationship between the dependent variable and the independent variable of interest. To do so, they can use `idid_viz_bivar` or the following code:

```{r xy_rel}
#| fig-asp: 0.8

data_partial <- 
  tibble(
    illiteracy_per = idid_partial_out(reg_ex, "Illiteracy"),
    income_per = idid_partial_out(reg_ex, "Income"),
    weight = (income_per - mean(income_per))^2
  ) |> 
  mutate(
    weight = weight/sum(weight),
    logweight = log10(weight * length(weight))
  )

data_partial |>
  ggplot(aes(x = income_per, y = illiteracy_per, color = logweight)) +
  geom_point(size = 2) +
  geom_rug(linewidth = 0.8) +
  # ggExtra::ggMarginal(type = "histogram") +
  geom_smooth(
    method = "lm", 
    color = idid_colors_table[["base"]],
    fill = idid_colors_table[["base"]], 
    alpha = 0.1) +
  theme_idid() +
  scale_color_idid() +
  labs(
    title = "Relationship between illiteracy and income",
    subtitle = "After partialling out controls",
    color = "Weight, as compared to the average weight",
    x = "Income (residualized)",
    y = "Illiteracy (residualized)"
  )
```

Such a mapping might be less legible when the sample size is large. In such instances, transparency or a bin or hex map can be useful tools to represent large numbers of observations.



